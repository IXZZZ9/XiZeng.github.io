---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

# üë§ About Me

I am a Master's student in Computer Science at [Boston University](https://www.bu.edu/), working as a Research Assistant in [Professor Reza Rawassizadeh's](https://sites.google.com/view/rezar) group.

My research interests lie at the intersection of Large Language Models (LLMs) and Reinforcement Learning, with a focus on:
- **Efficient LLM/VLM Training & Fine-tuning**: Investigating sparse attention mechanisms and low-rank adaptation (LoRA) techniques to accelerate convergence in billion-scale multimodal models. My work aims to optimize memory bandwidth and computational throughput for training VLMs in resource-constrained environments without compromising representational fidelity.
- **Deep Reinforcement Learning (DRL) in LLMs**: Advancing alignment techniques beyond standard RLHF by exploring novel policy optimization algorithms. My research focuses on stabilizing reward modeling and reducing variance in high-dimensional token spaces to improve reasoning capabilities and safety constraints.
- **Multi-Agent Systems & Theory of Mind**: Developing decentralized coordination frameworks where LLM-based agents exhibit emergent cooperative behaviors. My work involves optimizing communication protocols and consensus mechanisms to enable complex task decomposition and collaborative problem-solving among autonomous agents.
- **Continual Learning & Catastrophic Forgetting**: Addressing the stability-plasticity dilemma in sequential LLM fine-tuning through orthogonal gradient projection methods and invariant subspace identification. My research aims to preserve pre-trained general knowledge while adapting models to domain-specific downstream tasks.


# üî• News
- *2025.9*: &nbsp;üéâüéâ GradES paper is available on arXiv!

# üìù Publications

(‚Ä† indicates equal contribution)


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv</div><img src='images/GradES.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

GradES: Significantly Faster Training in Transformers with Gradient-Based Early Stopping

Q. Wen‚Ä†, **Xi Zeng‚Ä†**, Z. Zhou, S. Liu, M. Hosseinzadeh, N. Su, and R. Rawassizadeh


[![GitHub](https://img.shields.io/badge/GitHub-Code-fedcba?style=flat&logo=github)](https://github.com/IXZZZ9/GradES)![](https://img.shields.io/github/stars/IXZZZ9/GradES?style=social) [![arXiv](https://img.shields.io/badge/arXiv-2509.01842-b31b1b?style=flat&logo=arxiv)](https://arxiv.org/abs/2509.01842)[![PyPI version](https://badge.fury.io/py/grades.svg)](https://badge.fury.io/py/grades)
</div>
</div>


<div class='paper-box'><div class='paper-box-text' markdown="1">

Robust and Interpretable Silent Speech Recognition from High-Density sEMG Using Deep Forest

X. Tan, **Xi Zeng**, S. Fan, H. Zheng, X. Du, X. Ye, and C. Dai


- Novel application of Deep Forest's MDI for electrode importance mapping
- Achieves robust performance with 40% fewer electrodes
- Interpretable framework providing insights into speech-related muscle activation

</div>
</div>



<div class='paper-box'><div class='paper-box-text' markdown="1">

Analysis of Dyslipidemia Management Based on the DYSIS-China Study

X. Tan, Y. Pan, **Xi Zeng**, R. Yang, S. Zhao, and W. Zhao


- Large-scale analysis of dyslipidemia management patterns in Chinese populations
- Evidence-based recommendations for improving clinical practice

</div>
</div>


# üìñ Education
- *2024 - 2025*, Master of Computer Science, Boston University, Boston, MA
- *2021 - 2024*, Bachelor of Art, Computer Science, Rutgers University, Piscataway, NJ


# üìö Teaching Experience

**Teaching Assistant** @ [Boston University](https://www.bu.edu/)
*2025 - Present*
MET CS 767 Advanced ML and Neural Network
- Assessed assignments and provided constructive feedback on theoretical derivations and implementation details


# üíª Research Experience

**Research Assistant, Professor Reza Rawassizadeh's Group** @ [Boston University](https://www.bu.edu/cs/)
*2025 - Present*
- Presented weekly literature reviews of recent publications from top-tier ML/AI venues, facilitating critical discourse and encouraging intellectual exchange within the research group
- Iteratively developed research prototypes to validate theoretical hypotheses, conducting ablation studies and empirical evaluations to inform strategic research decisions
- Co-led the algorithmic development and experimental validation for high-impact research initiatives (GradES: Significantly Faster Training in Transformers with Gradient-Based Early Stopping, submitted to MLsys 2026)
- Architected production-quality codebases, implementing comprehensive refactoring and performance optimization, resulting in open-source releases on GitHub with reproducible benchmarks and documentation

**Research Assistant** @ [The Center for Intelligent Medical Electronics, Fudan University](https://www.fudan.edu.cn/)
*2024 - Present*
- Conducted hypothesis testing and significance analysis to validate experimental outcomes in biomedical signal processing applications
- Leveraged Mean Decrease Impurity (MDI) feature importance from Deep Forest to identify and rank critical electrode channels for optimal sensor placement
- Performed ablation studies by incrementally removing low-importance electrodes, identifying the optimal trade-off at 40% electrode retention that maintained 95% baseline performance
- Applied Wilcoxon signed-rank tests for non-parametric comparison and paired t-tests where normality assumptions are held, demonstrating statistical significance (p<0.05) in performance-efficiency gains


# üéñ Grants and Awards
- Dean's List, Kent State University


# üë• Academic and Professional Membership
- IEEE Member